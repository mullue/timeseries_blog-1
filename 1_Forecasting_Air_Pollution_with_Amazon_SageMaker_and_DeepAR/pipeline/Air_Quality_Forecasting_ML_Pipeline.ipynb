{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline for \"Forecasting Air Quality with Amazon SageMaker DeepAR\n",
    "\n",
    "In this example, we are going to build a ML Pipeline to automate air quality forecasting application with [AWS Step Functions Data Science SDK](https://aws-step-functions-data-science-sdk.readthedocs.io). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Pipeline\n",
    "\n",
    "### Outcome\n",
    "* Create the flow for ML process for air quality forcasting build/train/deploy\n",
    "* Create simple retrain flow\n",
    "\n",
    "### Design\n",
    "* Use Step Functions Data Science SDK to orchestrate the ML flow\n",
    "* Use SageMaker Processing to do data preprocessing, especially,\n",
    " * A common Docker image will be build for data retrieving (interact with Amazon Athena) and data/feature engineering\n",
    "* Use SageMaker Processing to do Model Evaluation\n",
    "* A scheduled job mechanism will be used to do model retraining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install --upgrade pip\n",
    "# !{sys.executable} -m pip install -qU awscli boto3 \"sagemaker==1.72.0\"\n",
    "# !{sys.executable} -m pip install -qU \"stepfunctions==1.1.1\"\n",
    "# !{sys.executable} -m pip show sagemaker stepfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import time\n",
    "import boto3\n",
    "import os, urllib.request\n",
    "import stepfunctions\n",
    "from stepfunctions import steps\n",
    "from stepfunctions.inputs import ExecutionInput\n",
    "from stepfunctions.steps.sagemaker import *\n",
    "from stepfunctions.steps.states import *\n",
    "from stepfunctions.workflow import Workflow\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.tuner import HyperparameterTuner, ContinuousParameter, IntegerParameter\n",
    "from sagemaker.model import Model\n",
    "\n",
    "session = boto3.Session()\n",
    "region = session.region_name\n",
    "account_id = session.client('sts').get_caller_identity().get('Account')\n",
    "bucket_name = f'{account_id}-openaq-forecasting'\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload existing model artifact to working bucket\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "os.makedirs('model', exist_ok=True)\n",
    "urllib.request.urlretrieve('https://d8pl0xx4oqh22.cloudfront.net/model.tar.gz', 'model/model.tar.gz')\n",
    "s3.upload_file('model/model.tar.gz', bucket_name, 'sagemaker/model/model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXISTING_MODEL_URI = f\"s3://{bucket_name}/sagemaker/model/model.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the workflow execution role. For the role arn, please refer to the output tab of the CloudFormation stack. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKFLOW_EXECUTION_ROLE = \"arn:aws:iam::593380422482:role/aqf-workshop-StepFunctionsWorkflowExecutionRole-1P06POQ2UPORW\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Docker image for SageMaker Processing\n",
    "\n",
    "Define your own processing container and install related dependencies.\n",
    "\n",
    "Below, you talk through how to create a processing container, and how to use a `ScriptProcessor` to run your own code within a container. Create a container support data preprocessing, feature engineering and model evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code buils the container using the docker command, creates an Amazon Elastic Container Registry (Amazon ECR) repository, and pushes the image to Amazon ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define repository name and uri variables\n",
    "ecr_repository = 'air-quality-forecasting-preprocessing'\n",
    "tag = ':latest'\n",
    "uri_suffix = 'amazonaws.com'\n",
    "if region in ['cn-north-1', 'cn-northwest-1']:\n",
    "    uri_suffix = 'amazonaws.com.cn'\n",
    "processing_repository_uri = f'{account_id}.dkr.ecr.{region}.{uri_suffix}/{ecr_repository + tag}'\n",
    "\n",
    "# build the image.\n",
    "!docker build -t $ecr_repository docker_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECR repository should have been created with CloudFormation stack. Uncomment below to create it in case it wasn't.\n",
    "#!aws ecr create-repository --repository-name $ecr_repository\n",
    "\n",
    "# Login and push the built docker image\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    "!docker tag {ecr_repository + tag} $processing_repository_uri\n",
    "!docker push $processing_repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the ProcessingStep\n",
    "We will now create the [ProcessingStep](https://aws-step-functions-data-science-sdk.readthedocs.io/en/stable/sagemaker.html#stepfunctions.steps.sagemaker.ProcessingStep) that will launch a SageMaker Processing Job.\n",
    "\n",
    "In the processing job script `preprocessing.py`, the actions will be done:\n",
    "\n",
    "* Create Athena table with external source - OpenAQ\n",
    "* Query Sydney OpenAQ data \n",
    "* Feature engineering on the dataset\n",
    "* Split training and test data \n",
    "* Store the data on S3 buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the preprocessing script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSING_SCRIPT_LOCATION = \"preprocessing.py\"\n",
    "input_code = sagemaker_session.upload_data(\n",
    "    PREPROCESSING_SCRIPT_LOCATION,\n",
    "    bucket = bucket_name,\n",
    "    key_prefix = \"preprocessing/code\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S3 locations of preprocessing output with training, test & all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = f\"s3://{bucket_name}/preprocessing/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ScriptProcessor` class lets you run a command inside the container, which you can use to run your own script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "preprocessing_processor = ScriptProcessor(\n",
    "    command = ['python3'],\n",
    "    image_uri = processing_repository_uri,\n",
    "    role = role,\n",
    "    instance_count = 1,\n",
    "    instance_type = 'ml.m5.xlarge',\n",
    "    max_runtime_in_seconds = 1200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step will use ScriptProcessor as defined in previous steps along with the inputs and outputs objects that are defined in the below steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    ProcessingInput(\n",
    "        source = input_code,\n",
    "        destination = \"/opt/ml/processing/input/code\",\n",
    "        input_name = \"code\"\n",
    "    )\n",
    "]\n",
    "\n",
    "outputs = [\n",
    "    ProcessingOutput(\n",
    "        source = \"/opt/ml/processing/output/all\",\n",
    "        destination = f\"{output_data}/all\",\n",
    "        output_name = \"all_data\"\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        source = \"/opt/ml/processing/output/train\",\n",
    "        destination = f\"{output_data}/train\",\n",
    "        output_name = \"train_data\"\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        source = \"/opt/ml/processing/output/test\",\n",
    "        destination = f\"{output_data}/test\",\n",
    "        output_name = \"test_data\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow Execution parameters\n",
    "execution_input = ExecutionInput(\n",
    "    schema = {\n",
    "        \"PreprocessingJobName\": str,\n",
    "        \"ToDoHPO\": bool,\n",
    "        \"ToDoTraining\": bool,\n",
    "        \"TrainingJobName\": str,\n",
    "        \"TuningJobName\": str,\n",
    "        \"ModelName\": str,\n",
    "        \"EndpointName\": str,\n",
    "        \"EvaluationProcessingJobName\": str\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_step = ProcessingStep(\n",
    "    \"AirQualityForecasting Pre-processing Step\",\n",
    "    processor = preprocessing_processor,\n",
    "    job_name = execution_input[\"PreprocessingJobName\"],\n",
    "    inputs = inputs,\n",
    "    outputs = outputs,\n",
    "    container_arguments = [\"--split-days\", \"30\"],\n",
    "    container_entrypoint = [\"python3\", \"/opt/ml/processing/input/code/preprocessing.py\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Setup tuning step and use choice state to decide whether we should do HPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = get_image_uri(region, \"forecasting-deepar\", \"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_output_path = f's3://{bucket_name}/sagemaker/tuning/output'\n",
    "\n",
    "ml_instance_type = 'ml.c5.9xlarge'\n",
    "\n",
    "tuning_estimator = sagemaker.estimator.Estimator(\n",
    "        sagemaker_session = sagemaker_session,\n",
    "        image_name = image_name,\n",
    "        role = role,\n",
    "        train_instance_count = 1,\n",
    "        train_instance_type = ml_instance_type,\n",
    "        base_job_name = 'deepar-openaq-demo',\n",
    "        output_path = tuning_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set static hyperparameters\n",
    "The static parameters are the ones we know to be the best based on previously run HPO jobs, as well as the non-tunable parameters like prediction length and time frequency that are set according to requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo = dict(\n",
    "    time_freq= '1H'\n",
    "    ,early_stopping_patience= 40\n",
    "    ,prediction_length= 48\n",
    "    ,num_eval_samples= 10\n",
    "\n",
    "    # default quantiles [0.1, 0.2, 0.3, ..., 0.9] is used\n",
    "    #,test_quantiles= quantiles\n",
    "    \n",
    "    # not setting these since HPO will use range of values\n",
    "    #,epochs= 400\n",
    "    #,context_length= 3\n",
    "    #,num_cells= 157\n",
    "    #,num_layers= 4\n",
    "    #,dropout_rate= 0.04\n",
    "    #,embedding_dimension= 12\n",
    "    #,mini_batch_size= 633\n",
    "    #,learning_rate= 0.0005\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set hyper-parameter ranges\n",
    "The hyperparameter ranges define the parameters we want the runer to search across.\n",
    "\n",
    "> Explore: Look in the [user guide](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar_hyperparameters.html) for DeepAR and add the recommended ranges for `embedding_dimension` to the below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_ranges = dict(\n",
    "    epochs= IntegerParameter(1, 1000)\n",
    "    ,context_length= IntegerParameter(7, 48)\n",
    "    ,num_cells= IntegerParameter(30,200)\n",
    "    ,num_layers= IntegerParameter(1,8)\n",
    "    ,dropout_rate= ContinuousParameter(0.0, 0.2)\n",
    "    ,embedding_dimension= IntegerParameter(1, 50)\n",
    "    ,mini_batch_size= IntegerParameter(32, 1028)\n",
    "    ,learning_rate= ContinuousParameter(.00001, .1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create HPO tunning job step\n",
    "Once we have the HPO tuner defined, we can define the tuning step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_estimator.set_hyperparameters(**hpo)\n",
    "\n",
    "hpo_tuner = HyperparameterTuner(\n",
    "    estimator = tuning_estimator, \n",
    "    objective_metric_name = 'train:final_loss',\n",
    "    objective_type = 'Minimize',\n",
    "    hyperparameter_ranges = hpo_ranges,\n",
    "    max_jobs = 2,\n",
    "    max_parallel_jobs = 1\n",
    ")\n",
    "\n",
    "hpo_data = dict(\n",
    "    train = f\"{output_data}/train\",\n",
    "    test = f\"{output_data}/test\"\n",
    ")\n",
    "# as long as HPO is selected, wait for completion.\n",
    "tuning_step = TuningStep(\n",
    "    \"HPO Step\",\n",
    "    tuner = hpo_tuner,\n",
    "    job_name = execution_input[\"TuningJobName\"],\n",
    "    data = hpo_data,\n",
    "    wait_for_completion = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "We create a DeepAR instance, which we will use to run a training job. This will be used to create a TrainingStep for the workflow.\n",
    "\n",
    "#### Setup the training job step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_output_path = f's3://{bucket_name}/sagemaker/training/output'\n",
    "training_estimator = sagemaker.estimator.Estimator(\n",
    "        sagemaker_session = sagemaker_session,\n",
    "        image_name = image_name,\n",
    "        role = role,\n",
    "        train_instance_count = 1,\n",
    "        train_instance_type = ml_instance_type,\n",
    "        base_job_name = 'deepar-openaq-demo',\n",
    "        output_path = training_output_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best hyper parameters for tuning\n",
    "hpo = dict(\n",
    "    time_freq= '1H'\n",
    "    ,early_stopping_patience= 40\n",
    "    ,prediction_length= 48\n",
    "    ,num_eval_samples= 10\n",
    "    #,test_quantiles= quantiles\n",
    "    ,epochs= 400\n",
    "    ,context_length= 3\n",
    "    ,num_cells= 157\n",
    "    ,num_layers= 4\n",
    "    ,dropout_rate= 0.04\n",
    "    ,embedding_dimension= 12\n",
    "    ,mini_batch_size= 633\n",
    "    ,learning_rate= 0.0005\n",
    ")\n",
    "training_estimator.set_hyperparameters(**hpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use all the features for training.\n",
    "data = dict(train = f\"{output_data}/all/all_features.json\")\n",
    "training_step = TrainingStep(\n",
    "    \"Training Step\",\n",
    "    estimator = training_estimator,\n",
    "    data = data,\n",
    "    job_name = execution_input[\"TrainingJobName\"],\n",
    "    wait_for_completion = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model Step\n",
    "\n",
    "In the following cell, we define a model step that will create a model in Amazon SageMaker using the artifacts created during the TrainingStep. See  [ModelStep](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/sagemaker.html#stepfunctions.steps.sagemaker.ModelStep) in the AWS Step Functions Data Science SDK documentation to learn more.\n",
    "\n",
    "The model creation step typically follows the training step. The Step Functions SDK provides the [get_expected_model](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/sagemaker.html#stepfunctions.steps.sagemaker.TrainingStep.get_expected_model) method in the TrainingStep class to provide a reference for the trained model artifacts. Please note that this method is only useful when the ModelStep directly follows the TrainingStep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_step = steps.ModelStep(\n",
    "    \"Save Model\",\n",
    "    model = training_step.get_expected_model(),\n",
    "    model_name = execution_input[\"ModelName\"],\n",
    "    result_path = \"$.ModelStepResults\"\n",
    ")\n",
    "\n",
    "# for deploying existing model\n",
    "existing_model_name = f\"aqf-model-{uuid.uuid1().hex}\"\n",
    "existing_model = Model(\n",
    "    model_data = EXISTING_MODEL_URI,\n",
    "    image = image_name,\n",
    "    role = role,\n",
    "    name = existing_model_name\n",
    ")\n",
    "existing_model_step = steps.ModelStep(\n",
    "    \"Existing Model\",\n",
    "    model = existing_model,\n",
    "    model_name = execution_input[\"ModelName\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Endpoint Configuration Step\n",
    "In the following cell we create an endpoint configuration step. See [EndpointConfigStep](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/sagemaker.html#stepfunctions.steps.sagemaker.EndpointConfigStep) in the AWS Step Functions Data Science SDK documentation to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_step = steps.EndpointConfigStep(\n",
    "    \"Create Model Endpoint Config\",\n",
    "    endpoint_config_name = execution_input[\"ModelName\"],\n",
    "    model_name = execution_input[\"ModelName\"],\n",
    "    initial_instance_count = 1,\n",
    "    instance_type = 'ml.c5.xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the Model Endpoint Step\n",
    "In the following cell, we create the Endpoint step to deploy the new model as a managed API endpoint, updating an existing SageMaker endpoint if our choice state is sucessful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_step = steps.EndpointStep(\n",
    "    \"Update Model Endpoint\",\n",
    "    endpoint_name = execution_input[\"EndpointName\"],\n",
    "    endpoint_config_name = execution_input[\"ModelName\"],\n",
    "    update = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup workflow process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `Fail` state to mark the workflow failed in case any of the steps fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_state_sagemaker_pipeline_step_failure = Fail(\n",
    "    \"ML Workflow failed\", cause = \"SageMakerPipelineStepFailed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = Chain([training_step, model_step, endpoint_config_step, endpoint_step])\n",
    "deploy_existing_model_path = Chain([existing_model_step, endpoint_config_step, endpoint_step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choice state\n",
    "\n",
    "Now, we need to setup choice state for choose HPO / Training or not. See *Choice Rules* in the [AWS Step Functions Data Science SDK documentation](https://aws-step-functions-data-science-sdk.readthedocs.io) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stepfunctions.steps import *\n",
    "\n",
    "hpo_choice = Choice(\n",
    "    \"To do HPO?\"\n",
    ")\n",
    "training_choice = Choice(\n",
    "    \"To do Model Training?\"\n",
    ")\n",
    "\n",
    "# refer to execution input variable with required format - not user friendly.\n",
    "hpo_choice.add_choice(\n",
    "    rule = ChoiceRule.BooleanEquals(variable = \"$$.Execution.Input['ToDoHPO']\", value = True),\n",
    "    next_step = tuning_step\n",
    ")\n",
    "hpo_choice.add_choice(\n",
    "    rule = ChoiceRule.BooleanEquals(variable = \"$$.Execution.Input['ToDoHPO']\", value = False),\n",
    "    next_step = training_choice\n",
    ")\n",
    "training_choice.add_choice(\n",
    "    rule = ChoiceRule.BooleanEquals(variable = \"$$.Execution.Input['ToDoTraining']\", value = True),\n",
    "    next_step = training_path\n",
    ")\n",
    "training_choice.add_choice(\n",
    "    rule = ChoiceRule.BooleanEquals(variable = \"$$.Execution.Input['ToDoTraining']\", value = False),\n",
    "    next_step = deploy_existing_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the Error handling in the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_state_processing = stepfunctions.steps.states.Catch(\n",
    "    error_equals = [\"States.TaskFailed\"],\n",
    "    next_step = failed_state_sagemaker_pipeline_step_failure   \n",
    ")\n",
    "processing_step.add_catch(catch_state_processing)\n",
    "tuning_step.add_catch(catch_state_processing)\n",
    "training_step.add_catch(catch_state_processing)\n",
    "model_step.add_catch(catch_state_processing)\n",
    "endpoint_config_step.add_catch(catch_state_processing)\n",
    "endpoint_step.add_catch(catch_state_processing)\n",
    "existing_model_step.add_catch(catch_state_processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create StepFunctions Workflow execution Input schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_job_name = f\"aqf-preprocessing-{uuid.uuid1().hex}\"\n",
    "tuning_job_name = f\"aqf-tuning-{uuid.uuid1().hex}\"\n",
    "training_job_name = f\"aqf-training-{uuid.uuid1().hex}\"\n",
    "model_job_name = f\"aqf-model-{uuid.uuid1().hex}\"\n",
    "endpoint_job_name = f\"aqf-endpoint-{uuid.uuid1().hex}\"\n",
    "evaluation_job_name = f\"aqf-evaluation-{uuid.uuid1().hex}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and execute the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workflow_graph = Chain([processing_step, hpo_choice])\n",
    "workflow_graph = Chain([processing_step, hpo_choice])\n",
    "workflow = Workflow(\n",
    "    name = \"AirQualityForecastingWorkflow2-02\",\n",
    "    definition = workflow_graph,\n",
    "    role = WORKFLOW_EXECUTION_ROLE\n",
    ")\n",
    "workflow.create()\n",
    "# update() to ensure existing workflow can get updated as create() just return ARN for the existing one.\n",
    "workflow.update(definition = workflow_graph) \n",
    "\n",
    "# execute workflow\n",
    "execution = workflow.execute(\n",
    "    inputs = {\n",
    "        \"PreprocessingJobName\": preprocessing_job_name,\n",
    "        \"ToDoHPO\": False,\n",
    "        \"ToDoTraining\": False,\n",
    "        \"TrainingJobName\": training_job_name,\n",
    "        \"TuningJobName\": tuning_job_name,\n",
    "        \"ModelName\": model_job_name,\n",
    "        \"EndpointName\": endpoint_job_name,\n",
    "        \"EvaluationProcessingJobName\": evaluation_job_name\n",
    "    }\n",
    ")\n",
    "execution_output = execution.get_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.render_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Pending] Create inferences (predictions)\n",
    "\n",
    "Now that we have a trained model, we need to evaluate it using the holdout data. Using this holdout data is only needed when you first are creating the model in order to get an idea of how the model will peform against new data in production. After the model is running in production, it is better to always retrain the model on all available data, and then monitor model perfromance over time against a trailing set of historical data.\n",
    "\n",
    "#### Generate test sets to predict\n",
    "To get an idea of how the model peforms, we will create predictions on a 12 hour rolling basis for all of the  locations, and then graph and compare them to the actuals. The method below generates the features from the hold out set to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from datetime import date, timedelta\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def filter_dates(df, min_time, max_time, frequency):\n",
    "    min_time = None if min_time is None else pd.to_datetime(min_time)\n",
    "    max_time = None if max_time is None else pd.to_datetime(max_time)\n",
    "    interval = pd.Timedelta(frequency)\n",
    "    \n",
    "    def _filter_dates(r): \n",
    "        if min_time is not None and r['start'] < min_time:\n",
    "            start_idx = int((min_time - r['start']) / interval)\n",
    "            r['target'] = r['target'][start_idx:]\n",
    "            r['start'] = min_time\n",
    "        \n",
    "        end_time = r['start'] + len(r['target']) * interval\n",
    "        if max_time is not None and end_time > max_time:\n",
    "            end_idx = int((end_time - max_time) / interval)\n",
    "            r['target'] = r['target'][:-end_idx]\n",
    "            \n",
    "        return r\n",
    "    \n",
    "    filtered = df.apply(_filter_dates, axis=1) \n",
    "    filtered = filtered[filtered['target'].str.len() > 0]\n",
    "    return filtered\n",
    "\n",
    "def get_tests(features, split_dates, frequency, context_length, prediction_length):\n",
    "    tests = []\n",
    "    end_date_delta = pd.Timedelta(f'{frequency} hour') * context_length\n",
    "    prediction_id = 0\n",
    "    for split_date in split_dates:\n",
    "        context_end = split_date + end_date_delta\n",
    "        test = filter_dates(features, split_date, context_end, f'{frequency}H')\n",
    "        test['prediction_start'] = context_end\n",
    "        test['prediction_id'] = prediction_id\n",
    "        test['start'] = test['start'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        tests.append(test)\n",
    "        prediction_id += 1\n",
    "        \n",
    "    tests = pd.concat(tests).reset_index().set_index(['id', 'prediction_id', 'prediction_start']).sort_index()\n",
    "    return tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_data_uri = f\"{output_data}/test/test.json\"\n",
    "test_data_uri\n",
    "local_result_file = \"test.json\"\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(bucket_name).download_file(\"preprocessing/output/test/test.json\", local_result_file)\n",
    "test = pd.read_json(local_result_file, orient=\"records\", lines = True, convert_dates=['start'])\n",
    "#test.reset_index(inplace=True)\n",
    "test.index.set_names(['id'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ten_days_ago = date.today() - timedelta(days = 10)\n",
    "test_dates = pd.date_range(ten_days_ago, periods = 216, freq = '1H')\n",
    "tests = get_tests(test, test_dates, '1', 3, 48)\n",
    "tests.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the endpoint\n",
    "From the above, you can see that will will need to call our endpoint 4060 times for each of our tests, as we are back testing every hour, across all locations for the previous 10 days. \n",
    "Before we call the endpoint with all of the tests we have generated, let's first try calling it for just one location and time. The request passes in an array of features, one for each location, as well as configuration settings.\n",
    "\n",
    "> **Try this:** Modify the request to get a different quantile, or the predictions for a different test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictor = Predictor(\n",
    "    endpoint_name, \n",
    "    serializer=sagemaker.serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer()\n",
    ")\n",
    "\n",
    "features = tests[['start','target','cat']].iloc[0].to_dict()\n",
    "json.dumps(predictor.predict({\n",
    "    'instances': [features]\n",
    "    ,'configuration': {\n",
    "        'num_samples': 20\n",
    "        ,'output_types': ['quantiles']\n",
    "        ,'quantiles': ['0.5']\n",
    "    }\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions = predict(predictor.endpoint_name, tests, quantiles) \n",
    "predictions.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
