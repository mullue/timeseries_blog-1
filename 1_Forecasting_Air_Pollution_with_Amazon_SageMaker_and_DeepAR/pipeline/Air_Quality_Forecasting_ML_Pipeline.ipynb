{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline for \"Forecasting Air Quality with Amazon SageMaker DeepAR\n",
    "\n",
    "In this example, we are going to build a ML Pipeline to automate air quality forecasting application with [AWS Step Functions Data Science SDK](https://aws-step-functions-data-science-sdk.readthedocs.io). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Pipeline\n",
    "\n",
    "### Outcome\n",
    "* Create the flow for ML process for air quality forcasting build/train/deploy\n",
    "* Create simple retrain flow\n",
    "\n",
    "### Design\n",
    "* Use Step Functions Data Science SDK to orchestrate the ML flow\n",
    "* Use SageMaker Processing to do data preprocessing, especially,\n",
    " * A common Docker image will be build for data retrieving (interact with Amazon Athena) and data/feature engineering\n",
    "* Use SageMaker Processing to do Model Evaluation\n",
    "* A scheduled job mechanism will be used to do model retraining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.5.5.tar.gz (293 kB)\n",
      "\u001b[K     |████████████████████████████████| 293 kB 26.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: boto3>=1.14.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (1.14.51)\n",
      "Collecting google-pasta\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (3.13.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (0.1.5)\n",
      "Collecting smdebug-rulesconfig==0.1.5\n",
      "  Using cached smdebug_rulesconfig-0.1.5-py2.py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (20.3)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.18.0,>=1.17.51 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker) (1.17.51)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-pasta->sagemaker) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker) (46.1.3.post20200330)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging>=20.0->sagemaker) (2.4.6)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.51->boto3>=1.14.12->sagemaker) (0.15.2)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.26,>=1.20; python_version != \"3.4\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.51->boto3>=1.14.12->sagemaker) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.51->boto3>=1.14.12->sagemaker) (2.8.1)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.5.5-py2.py3-none-any.whl size=415596 sha256=093aeed935e58d031f10ff82ead34292fec7520eb5c069ea69c216331a63ad81\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/0d/55/96/5edc5b32f17c32cf305789d97dff9688167dc93ea4e4af6667\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: google-pasta, smdebug-rulesconfig, sagemaker\n",
      "  Attempting uninstall: smdebug-rulesconfig\n",
      "    Found existing installation: smdebug-rulesconfig 0.1.4\n",
      "    Uninstalling smdebug-rulesconfig-0.1.4:\n",
      "      Successfully uninstalled smdebug-rulesconfig-0.1.4\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 1.72.0\n",
      "    Uninstalling sagemaker-1.72.0:\n",
      "      Successfully uninstalled sagemaker-1.72.0\n",
      "Successfully installed google-pasta-0.2.0 sagemaker-2.5.5 smdebug-rulesconfig-0.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Docker Image for SageMaker Processing\n",
    "\n",
    "Define your own processing container and install related dependencies.\n",
    "\n",
    "Below, you talk through how to create a processing container, and how to use a `ScriptProcessor` to run your own code within a container. Create a container support data preprocessing, feature engineering and model evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subfolder for docker \n",
    "!mkdir docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the Dockerfile to create processing container. Install PyAthena, pandas and GeoPandas into it. You can install your own dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing docker/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile docker/Dockerfile\n",
    "\n",
    "FROM python:3.7-slim-buster\n",
    "    \n",
    "RUN pip install PyAthena[Pandas] geopandas scikit-learn\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "\n",
    "ENTRYPOINT [\"python3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code buils the container using the docker command, creates an Amazon Elastic Container Registry (Amazon ECR) repository, and pushes the image to Amazon ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "ecr_repository = 'aq-forecasting-processing-container'\n",
    "tag = ':latest'\n",
    "\n",
    "uri_suffix = 'amazonaws.com'\n",
    "if region in ['cn-north-1', 'cn-northwest-1']:\n",
    "    uri_suffix = 'amazonaws.com.cn'\n",
    "processing_repository_uri = f'{account_id}.dkr.ecr.{region}.{uri_suffix}/{ecr_repository + tag}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'593380422482.dkr.ecr.us-east-1.amazonaws.com/aq-forecasting-processing-container:latest'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing_repository_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  2.048kB\n",
      "Step 1/4 : FROM python:3.7-slim-buster\n",
      "3.7-slim-buster: Pulling from library/python\n",
      "\n",
      "\u001b[1Bf8d1c412: Pulling fs layer \n",
      "\u001b[1B2574cc82: Pulling fs layer \n",
      "\u001b[1B6349c99d: Pulling fs layer \n",
      "\u001b[1Bc0b72728: Pulling fs layer \n",
      "\u001b[1BDigest: sha256:4731bee5e891e5bf8af43f0bfd3c25f8b999eb7ef6757f756f4cb9836c929eeb5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\n",
      "Status: Downloaded newer image for python:3.7-slim-buster\n",
      " ---> 4d4a9832278b\n",
      "Step 2/4 : RUN pip install PyAthena[Pandas] geopandas scikit-learn\n",
      " ---> Running in badac19e526a\n",
      "Collecting PyAthena[Pandas]\n",
      "  Downloading PyAthena-1.11.1-py2.py3-none-any.whl (49 kB)\n",
      "Collecting geopandas\n",
      "  Downloading geopandas-0.8.1-py2.py3-none-any.whl (962 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
      "Collecting tenacity>=4.1.0\n",
      "  Downloading tenacity-6.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting boto3>=1.4.4\n",
      "  Downloading boto3-1.14.60-py2.py3-none-any.whl (129 kB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Collecting botocore>=1.5.52\n",
      "  Downloading botocore-1.17.60-py2.py3-none-any.whl (6.6 MB)\n",
      "Collecting pandas>=0.24.0; extra == \"pandas\"\n",
      "  Downloading pandas-1.1.2-cp37-cp37m-manylinux1_x86_64.whl (10.5 MB)\n",
      "Collecting pyarrow>=0.15.0; extra == \"pandas\"\n",
      "  Downloading pyarrow-1.0.1-cp37-cp37m-manylinux2014_x86_64.whl (17.3 MB)\n",
      "Collecting shapely\n",
      "  Downloading Shapely-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting pyproj>=2.2.0\n",
      "  Downloading pyproj-2.6.1.post1-cp37-cp37m-manylinux2010_x86_64.whl (10.9 MB)\n",
      "Collecting fiona\n",
      "  Downloading Fiona-1.8.17-cp37-cp37m-manylinux1_x86_64.whl (14.8 MB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "Collecting numpy>=1.13.3\n",
      "  Downloading numpy-1.19.2-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting six>=1.9.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Collecting python-dateutil<3.0.0,>=2.1\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting urllib3<1.26,>=1.20; python_version != \"3.4\"\n",
      "  Downloading urllib3-1.25.10-py2.py3-none-any.whl (127 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting click-plugins>=1.0\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting attrs>=17\n",
      "  Downloading attrs-20.2.0-py2.py3-none-any.whl (48 kB)\n",
      "Collecting click<8,>=4.0\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting cligj>=0.5\n",
      "  Downloading cligj-0.5.0-py3-none-any.whl (5.7 kB)\n",
      "Collecting munch\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=2ac92ac157c7af806f7ec3e9517721d3a83b3f416a2606bc004ca9428b12102b\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "Successfully built future\n",
      "Installing collected packages: six, tenacity, jmespath, docutils, python-dateutil, urllib3, botocore, s3transfer, boto3, future, numpy, pytz, pandas, pyarrow, PyAthena, shapely, pyproj, click, click-plugins, attrs, cligj, munch, fiona, geopandas, scipy, threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed PyAthena-1.11.1 attrs-20.2.0 boto3-1.14.60 botocore-1.17.60 click-7.1.2 click-plugins-1.1.1 cligj-0.5.0 docutils-0.15.2 fiona-1.8.17 future-0.18.2 geopandas-0.8.1 jmespath-0.10.0 joblib-0.16.0 munch-2.5.0 numpy-1.19.2 pandas-1.1.2 pyarrow-1.0.1 pyproj-2.6.1.post1 python-dateutil-2.8.1 pytz-2020.1 s3transfer-0.3.3 scikit-learn-0.23.2 scipy-1.5.2 shapely-1.7.1 six-1.15.0 tenacity-6.2.0 threadpoolctl-2.1.0 urllib3-1.25.10\n",
      "Removing intermediate container badac19e526a\n",
      " ---> 42e9716cf4fd\n",
      "Step 3/4 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Running in 8f1a2385c839\n",
      "Removing intermediate container 8f1a2385c839\n",
      " ---> f1254048fa83\n",
      "Step 4/4 : ENTRYPOINT [\"python3\"]\n",
      " ---> Running in 0ce686786e70\n",
      "Removing intermediate container 0ce686786e70\n",
      " ---> ecaf0d894071\n",
      "Successfully built ecaf0d894071\n",
      "Successfully tagged aq-forecasting-processing-container:latest\n",
      "\n",
      "Unknown options: --registry_ids,593380422482\n",
      "{\n",
      "    \"repository\": {\n",
      "        \"repositoryArn\": \"arn:aws:ecr:us-east-1:593380422482:repository/aq-forecasting-processing-container\",\n",
      "        \"registryId\": \"593380422482\",\n",
      "        \"repositoryName\": \"aq-forecasting-processing-container\",\n",
      "        \"repositoryUri\": \"593380422482.dkr.ecr.us-east-1.amazonaws.com/aq-forecasting-processing-container\",\n",
      "        \"createdAt\": 1599891015.0,\n",
      "        \"imageTagMutability\": \"MUTABLE\",\n",
      "        \"imageScanningConfiguration\": {\n",
      "            \"scanOnPush\": false\n",
      "        },\n",
      "        \"encryptionConfiguration\": {\n",
      "            \"encryptionType\": \"AES256\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "The push refers to repository [593380422482.dkr.ecr.us-east-1.amazonaws.com/aq-forecasting-processing-container]\n",
      "\n",
      "\u001b[1B4b9d8fee: Preparing \n",
      "\u001b[1Be5632dc8: Preparing \n",
      "\u001b[1B857805ec: Preparing \n",
      "\u001b[1B87503449: Preparing \n",
      "\u001b[1B6688d36c: Preparing \n",
      "\u001b[1Bno basic auth credentials\n"
     ]
    }
   ],
   "source": [
    "# @todo consider using CFN template to create ECR repo and only manage the docker image build and push.\n",
    "!docker build -t $ecr_repository docker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "An error occurred (RepositoryAlreadyExistsException) when calling the CreateRepository operation: The repository with name 'aq-forecasting-processing-container' already exists in the registry with id '593380422482'\n",
      "The push refers to repository [593380422482.dkr.ecr.us-east-1.amazonaws.com/aq-forecasting-processing-container]\n",
      "\n",
      "\u001b[1B4b9d8fee: Preparing \n",
      "\u001b[1Be5632dc8: Preparing \n",
      "\u001b[1B857805ec: Preparing \n",
      "\u001b[1B87503449: Preparing \n",
      "\u001b[1B6688d36c: Preparing \n",
      "\u001b[6B4b9d8fee: Pushed   547.8MB/538.5MB\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[6A\u001b[2K\u001b[2A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[6A\u001b[2K\u001b[2A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2Klatest: digest: sha256:6f8e109b332d84d9949a0e1c7dbfb77bb6ce62c56e04af1fabce82db13ac4a4a size: 1583\n"
     ]
    }
   ],
   "source": [
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    "!aws ecr create-repository --repository-name $ecr_repository\n",
    "!docker tag {ecr_repository + tag} $processing_repository_uri\n",
    "!docker push $processing_repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below cell writes a file `preprocessing.py`, which contains the pre-processing script. You can update the script, and rerun the cell to overwrite `preprocessing.py`. You run this as a processing job in the next cell. In this script, the actions will be done:\n",
    "\n",
    "* Create Athena table with external source - OpenAQ\n",
    "* Query OpenAQ data \n",
    "* Feature engineering on the dataset\n",
    "* Split and store the data on S3 buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import boto3, time, s3fs, json, warnings, os\n",
    "import urllib.request\n",
    "from datetime import date, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# the train test split date is used to split each time series into train and test sets\n",
    "train_test_split_date = date.today() - timedelta(days = 30)\n",
    "\n",
    "# the sampling frequency determines the number of hours per sample\n",
    "# and is used for aggregating and filling missing values\n",
    "frequency = '1'\n",
    "\n",
    "# prediction length is how many hours into future to predict values for\n",
    "prediction_length = 48\n",
    "\n",
    "# context length is how many prior time steps the predictor needs to make a prediction\n",
    "context_length = 3\n",
    "\n",
    "warnings.filterwarning('ignore')\n",
    "\n",
    "session = boto3.Session()\n",
    "region = session.region_name\n",
    "account = session.client('sts').get_caller_identity().get('Account')\n",
    "bucket_name = f\"{account_id}-openaq-lab\"\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# @todo to evaluate whether we should store existing model.tar.gz onto s3 bucket.\n",
    "\n",
    "# processing Athena\n",
    "def athena_execute(query_file, ext, wait):\n",
    "    with open(query_file) as f:\n",
    "        query_str = f.read()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ScriptProcessor` class lets you run a command inside the container, which you can use to run your own script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "preprocessing_processor = ScriptProcessor(\n",
    "    command = ['python3'],\n",
    "    image_uri = processing_repository_uri,\n",
    "    role = role,\n",
    "    instance_count = 1,\n",
    "    instance_type = 'ml.m5.xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
